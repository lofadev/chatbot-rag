import os
import shutil
import gradio as gr
from langchain.document_loaders import PyMuPDFLoader, Docx2txtLoader, TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from dotenv import load_dotenv

# Táº£i cÃ¡c biáº¿n mÃ´i trÆ°á»ng (cho OpenAI API key)
load_dotenv()

# CÃ¡c thÆ° má»¥c
DOCUMENTS_DIR = "documents"
INDEX_DIR = "faiss_index"

# Äáº£m báº£o cÃ¡c thÆ° má»¥c tá»“n táº¡i
os.makedirs(DOCUMENTS_DIR, exist_ok=True)
os.makedirs(INDEX_DIR, exist_ok=True)

# Cáº¥u hÃ¬nh máº·c Ä‘á»‹nh cho chunking
DEFAULT_CONFIG = {
    "chunk_size": 1000,
    "chunk_overlap": 200,
    "strategy": "recursive",  # "recursive", "character", "token"
    "separators": ["\n\n", "\n", " ", ""],
    "length_function": "len",
}


# HÃ m láº¥y loader phÃ¹ há»£p dá»±a trÃªn pháº§n má»Ÿ rá»™ng cá»§a file
def get_loader(file_path):
    ext = os.path.splitext(file_path)[1].lower()
    if ext == ".pdf":
        return PyMuPDFLoader(file_path, extract_tables="markdown", mode="page")
    elif ext == ".docx":
        return Docx2txtLoader(file_path)
    elif ext in [".txt", ".md"]:
        return TextLoader(file_path)
    else:
        raise ValueError("Unsupported file format")


# HÃ m xá»­ lÃ½ má»™t tÃ i liá»‡u Ä‘Æ¡n láº» vá»›i metadata chi tiáº¿t
def ingest_document(file_path, config=None):
    if config is None:
        config = DEFAULT_CONFIG.copy()

    filename = os.path.basename(file_path)
    loader = get_loader(file_path)
    documents = loader.load()

    # Cáº£i thiá»‡n metadata cho má»—i document
    for doc in documents:
        doc.metadata.update(
            {
                "source_file": filename,
                "file_path": file_path,
                "file_type": os.path.splitext(filename)[1].lower(),
                "processed_time": str(os.path.getmtime(file_path)),
            }
        )

        # ThÃªm page number náº¿u cÃ³ (cá»™ng thÃªm 1 Ä‘á»ƒ báº¯t Ä‘áº§u tá»« trang 1)
        if "page" in doc.metadata:
            page_info = doc.metadata.get("page")
            if page_info is not None and isinstance(page_info, (int, float)):
                doc.metadata["page_number"] = int(page_info) + 1
            else:
                doc.metadata["page_number"] = page_info
        else:
            # KhÃ´ng cÃ³ thÃ´ng tin trang
            doc.metadata["page_number"] = "N/A"

    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=config["chunk_size"],
        chunk_overlap=config["chunk_overlap"],
        length_function=len,
        separators=config.get("separators", ["\n\n", "\n", " ", ""]),
    )
    chunks = text_splitter.split_documents(documents)

    # ThÃªm thÃ´ng tin chunk index cho má»—i chunk
    for i, chunk in enumerate(chunks):
        chunk.metadata.update(
            {
                "chunk_index": i,
                "chunk_size": len(chunk.page_content),
                "total_chunks": len(chunks),
            }
        )

    return chunks


# HÃ m xÃ¢y dá»±ng hoáº·c xÃ¢y dá»±ng láº¡i index vá»›i cáº¥u hÃ¬nh chunking
def build_index(config=None):
    if config is None:
        config = DEFAULT_CONFIG.copy()

    if os.path.exists(INDEX_DIR):
        shutil.rmtree(INDEX_DIR)

    all_chunks = []
    processed_files = []

    for filename in os.listdir(DOCUMENTS_DIR):
        if filename.startswith("."):  # Bá» qua hidden files
            continue

        file_path = os.path.join(DOCUMENTS_DIR, filename)
        if os.path.isfile(file_path):
            try:
                chunks = ingest_document(file_path, config)
                all_chunks.extend(chunks)
                processed_files.append(f"{filename}: {len(chunks)} chunks")
            except Exception as e:
                processed_files.append(f"{filename}: Error - {str(e)}")

    if all_chunks:
        embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
        vectorstore = FAISS.from_documents(all_chunks, embeddings)
        vectorstore.save_local(INDEX_DIR)

        result = f"Index built successfully with {len(all_chunks)} total chunks.\n"
        result += f"Chunking strategy: {config['strategy']}, "
        result += f"Chunk size: {config['chunk_size']}, "
        result += f"Overlap: {config['chunk_overlap']}\n\n"
        result += "Processed files:\n" + "\n".join(processed_files)
        return result
    else:
        return "No documents to index."


# HÃ m táº£i vectorstore
def load_vectorstore():
    if os.path.exists(os.path.join(INDEX_DIR, "index.faiss")):
        embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
        return FAISS.load_local(
            INDEX_DIR, embeddings, allow_dangerous_deserialization=True
        )
    return None


# HÃ m táº£i lÃªn vÃ  xá»­ lÃ½ file
def upload_file(file):
    if file is None:
        return "No file uploaded."

    filename = os.path.basename(file.name)
    file_path = os.path.join(DOCUMENTS_DIR, filename)
    shutil.copy(file.name, file_path)

    config = DEFAULT_CONFIG.copy()
    result = build_index(config)  # Rebuild index sau khi táº£i lÃªn
    return f"File {filename} uploaded successfully.\n\n{result}"


# HÃ m liá»‡t kÃª cÃ¡c tÃ i liá»‡u vá»›i thÃ´ng tin chi tiáº¿t
def list_documents():
    files = os.listdir(DOCUMENTS_DIR)
    if not files:
        return "No documents."

    file_info = []
    for filename in files:
        if filename.startswith("."):
            continue
        file_path = os.path.join(DOCUMENTS_DIR, filename)
        if os.path.isfile(file_path):
            size = os.path.getsize(file_path)
            size_mb = round(size / (1024 * 1024), 2)
            ext = os.path.splitext(filename)[1].lower()
            file_info.append(f"ğŸ“„ {filename} ({size_mb} MB, {ext})")

    return "\n".join(file_info) if file_info else "No valid documents."


# HÃ m xÃ³a tÃ i liá»‡u
def delete_document(filename):
    file_path = os.path.join(DOCUMENTS_DIR, filename)
    if os.path.exists(file_path):
        os.remove(file_path)
        config = DEFAULT_CONFIG.copy()
        result = build_index(config)  # Rebuild index sau khi xÃ³a
        return f"File {filename} deleted successfully.\n\n{result}"
    return "File not found."


# HÃ m Ä‘Ã¡nh index láº¡i vá»›i cáº¥u hÃ¬nh hiá»‡n táº¡i
def reindex():
    config = DEFAULT_CONFIG.copy()
    return build_index(config)


# Prompt tÃ¹y chá»‰nh cho LLM vá»›i hÆ°á»›ng dáº«n trÃ­ch dáº«n chi tiáº¿t
prompt_template = """
Báº¡n lÃ  má»™t trá»£ lÃ½ AI tÃ¬m kiáº¿m thÃ´ng tin thÃ´ng minh, báº¡n cÃ³ thá»ƒ tÃ¬m kiáº¿m thÃ´ng tin trong cÃ¡c tÃ i liá»‡u Ä‘Ã£ Ä‘Æ°á»£c Ä‘Ã¡nh index.
Sá»­ dá»¥ng CHÃNH XÃC thÃ´ng tin tá»« cÃ¡c Ä‘oáº¡n vÄƒn báº£n dÆ°á»›i Ä‘Ã¢y Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i. 
Náº¿u báº¡n khÃ´ng biáº¿t cÃ¢u tráº£ lá»i tá»« ngá»¯ cáº£nh Ä‘Ã£ cho, hÃ£y nÃ³i ráº±ng báº¡n khÃ´ng biáº¿t, Ä‘á»«ng bá»‹a Ä‘áº·t thÃ´ng tin.
Sá»­ dá»¥ng ngÃ´n ngá»¯ tá»± nhiÃªn, thÃ¢n thiá»‡n vá»›i ngÆ°á»i dÃ¹ng.
Tráº£ lá»i báº±ng cÃ¹ng ngÃ´n ngá»¯ vá»›i cÃ¢u há»i (Tiáº¿ng Viá»‡t hoáº·c Tiáº¿ng Anh).
Khi cÃ¢u há»i báº±ng tiáº¿ng Anh nhÆ°ng context báº±ng tiáº¿ng Viá»‡t, hÃ£y hiá»ƒu context tiáº¿ng Viá»‡t, trÃ­ch xuáº¥t thÃ´ng tin liÃªn quan, vÃ  soáº¡n cÃ¢u tráº£ lá»i hoÃ n chá»‰nh báº±ng tiáº¿ng Anh. NgÆ°á»£c láº¡i Tiáº¿ng Anh cÅ©ng váº­y.

QUY Táº®C TRÃCH DáºªN Báº®T BUá»˜C:
- Báº®T BUá»˜C pháº£i trÃ­ch dáº«n nguá»“n cho Má»–I thÃ´ng tin báº¡n cung cáº¥p
- Sá»¬ Dá»¤NG CHÃNH XÃC citation Ä‘Ã£ Ä‘Æ°á»£c cung cáº¥p trong tá»«ng Ä‘oáº¡n vÄƒn báº£n
- Má»—i Ä‘oáº¡n vÄƒn báº£n Ä‘Ã£ cÃ³ sáºµn "Nguá»“n trÃ­ch dáº«n:" á»Ÿ cuá»‘i - PHáº¢I sá»­ dá»¥ng Ä‘Ãºng citation nÃ y
- KHÃ”NG Ä‘Æ°á»£c tá»± táº¡o citation má»›i, chá»‰ sá»­ dá»¥ng citation cÃ³ sáºµn trong ngá»¯ cáº£nh
- Khi tham kháº£o thÃ´ng tin tá»« má»™t Ä‘oáº¡n vÄƒn báº£n, LUÃ”N include citation cá»§a Ä‘oáº¡n Ä‘Ã³
- Náº¿u thÃ´ng tin Ä‘áº¿n tá»« nhiá»u Ä‘oáº¡n vÄƒn báº£n, liá»‡t kÃª Táº¤T Cáº¢ citations liÃªn quan

CÃCH TRÃCH DáºªN:
- Sau má»—i thÃ´ng tin, thÃªm citation trong ngoáº·c vuÃ´ng
- VÃ­ dá»¥: "Doanh thu nÄƒm 2023 lÃ  100 triá»‡u Ä‘á»“ng [bao_cao_tai_chinh.pdf, Trang 5]"
- Vá»›i nhiá»u nguá»“n: "ThÃ´ng tin nÃ y Ä‘Æ°á»£c xÃ¡c nháº­n [file1.pdf, Trang 2] [file2.pdf, Trang 7]"

Ngá»¯ cáº£nh vá»›i citation:
{context}

CÃ¢u há»i: {question}

Tráº£ lá»i chi tiáº¿t (Báº®T BUá»˜C bao gá»“m trÃ­ch dáº«n nguá»“n cho má»i thÃ´ng tin):
"""

PROMPT = PromptTemplate(
    template=prompt_template, input_variables=["context", "question"]
)


# HÃ m cáº£i thiá»‡n context vá»›i metadata chi tiáº¿t - chá»‰ hiá»ƒn thá»‹ file vÃ  trang
def format_docs_with_metadata(docs):
    formatted_docs = []
    for doc in docs:
        metadata = doc.metadata
        source_file = metadata.get("source_file", "Unknown file")

        # Xá»­ lÃ½ sá»‘ trang (Æ°u tiÃªn page_number Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½, khÃ´ng thÃ¬ xá»­ lÃ½ page gá»‘c)
        if "page_number" in metadata and metadata["page_number"] != "N/A":
            # page_number Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½ trong ingest_document
            display_page = metadata["page_number"]
            citation = f"[{source_file}, Trang {display_page}]"
        elif "page" in metadata and metadata["page"] != "N/A":
            # Fallback: sá»­ dá»¥ng page gá»‘c vÃ  cá»™ng thÃªm 1
            page_info = metadata["page"]
            if isinstance(page_info, (int, float)):
                display_page = int(page_info) + 1
            else:
                display_page = page_info
            citation = f"[{source_file}, Trang {display_page}]"
        else:
            # KhÃ´ng cÃ³ thÃ´ng tin trang, chá»‰ hiá»ƒn thá»‹ file
            citation = f"[{source_file}]"

        # Format content vá»›i citation rÃµ rÃ ng hÆ¡n - khÃ´ng hiá»ƒn thá»‹ thÃ´ng tin chunk
        content = f"=== ÄOáº N VÄ‚N Báº¢N Tá»ª {citation} ===\n{doc.page_content}\n=== Káº¾T THÃšC ÄOáº N VÄ‚N Báº¢N ===\nNguá»“n trÃ­ch dáº«n: {citation}"
        formatted_docs.append(content)

    return "\n\n---\n\n".join(formatted_docs)


# HÃ m cho há»i Ä‘Ã¡p vá»›i citation chÃ­nh xÃ¡c
def ask_question(question, num_results=5):
    vectorstore = load_vectorstore()
    if vectorstore is None:
        return "KhÃ´ng cÃ³ index nÃ o kháº£ dá»¥ng. Vui lÃ²ng táº£i lÃªn tÃ i liá»‡u trÆ°á»›c."

    # Táº¡o LLM
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

    # Táº¡o retriever
    retriever = vectorstore.as_retriever(search_kwargs={"k": num_results})

    # Retrieve documents
    relevant_docs = retriever.get_relevant_documents(question)

    if not relevant_docs:
        return "KhÃ´ng tÃ¬m tháº¥y thÃ´ng tin liÃªn quan trong tÃ i liá»‡u."

    # Format context vá»›i metadata chi tiáº¿t
    formatted_context = format_docs_with_metadata(relevant_docs)

    # Táº¡o prompt vá»›i context Ä‘Ã£ Ä‘Æ°á»£c format
    formatted_prompt = PROMPT.format(context=formatted_context, question=question)

    # Gá»i LLM vá»›i prompt Ä‘Ã£ format
    result = llm.invoke(formatted_prompt)

    # Tráº£ vá» ná»™i dung text tá»« response
    if hasattr(result, "content"):
        return result.content
    else:
        return str(result)


# Giao diá»‡n Gradio
with gr.Blocks(title="RAG Document QA System", theme=gr.themes.Default()) as demo:
    gr.Markdown("# ğŸ¤– RAG-based Document QA System")
    gr.Markdown(
        "Há»‡ thá»‘ng há»i Ä‘Ã¡p thÃ´ng minh dá»±a trÃªn tÃ i liá»‡u vá»›i kháº£ nÄƒng trÃ­ch dáº«n nguá»“n chi tiáº¿t"
    )

    with gr.Tab("ğŸ“„ Quáº£n lÃ½ TÃ i liá»‡u"):
        gr.Markdown("### Táº£i lÃªn vÃ  quáº£n lÃ½ tÃ i liá»‡u")

        with gr.Row():
            with gr.Column(scale=2):
                file_upload = gr.File(
                    label="Chá»n tÃ i liá»‡u (PDF, DOCX, TXT, MD)",
                    file_types=[".pdf", ".docx", ".txt", ".md"],
                )
                upload_button = gr.Button("ğŸ“¤ Táº£i lÃªn vÃ  ÄÃ¡nh index", variant="primary")
                upload_output = gr.Textbox(label="Tráº¡ng thÃ¡i táº£i lÃªn", lines=5)

            with gr.Column(scale=1):
                list_button = gr.Button("ğŸ“‹ Liá»‡t kÃª tÃ i liá»‡u")
                documents_list = gr.Textbox(label="Danh sÃ¡ch tÃ i liá»‡u", lines=8)

        gr.Markdown("---")

        with gr.Row():
            delete_input = gr.Textbox(
                label="TÃªn file cáº§n xÃ³a", placeholder="VÃ­ dá»¥: document.pdf"
            )
            delete_button = gr.Button("ğŸ—‘ï¸ XÃ³a tÃ i liá»‡u", variant="stop")
            delete_output = gr.Textbox(label="Tráº¡ng thÃ¡i xÃ³a", lines=3)

        with gr.Row():
            reindex_button = gr.Button("ğŸ”„ ÄÃ¡nh index láº¡i toÃ n bá»™", variant="secondary")
            reindex_output = gr.Textbox(label="Tráº¡ng thÃ¡i Ä‘Ã¡nh index", lines=5)

        # Event handlers cho tab Admin
        upload_button.click(upload_file, inputs=file_upload, outputs=upload_output)
        list_button.click(list_documents, outputs=documents_list)
        delete_button.click(delete_document, inputs=delete_input, outputs=delete_output)
        reindex_button.click(reindex, outputs=reindex_output)

    with gr.Tab("ğŸ’¬ Há»i Ä‘Ã¡p"):
        gr.Markdown("### Äáº·t cÃ¢u há»i vá» tÃ i liá»‡u")
        gr.Markdown(
            "Há»‡ thá»‘ng sáº½ tÃ¬m kiáº¿m thÃ´ng tin liÃªn quan vÃ  tráº£ lá»i kÃ¨m trÃ­ch dáº«n nguá»“n"
        )

        with gr.Row():
            with gr.Column(scale=3):
                chatbot = gr.Chatbot(
                    height=500, label="Cuá»™c há»™i thoáº¡i", show_label=True
                )

                with gr.Row():
                    msg = gr.Textbox(
                        label="CÃ¢u há»i cá»§a báº¡n",
                        placeholder="VÃ­ dá»¥: TÃ i liá»‡u nÃ³i gÃ¬ vá» chÃ­nh sÃ¡ch báº£o máº­t?",
                        lines=2,
                        scale=4,
                    )
                    submit_btn = gr.Button("ğŸš€ Gá»­i", variant="primary", scale=1)
                    clear_btn = gr.Button("ğŸ—‘ï¸ XÃ³a", variant="secondary", scale=1)

            with gr.Column(scale=1):
                gr.Markdown("### âš¡ TÃ¹y chá»n tÃ¬m kiáº¿m")
                num_results = gr.Slider(
                    minimum=1,
                    maximum=10,
                    value=5,
                    step=1,
                    label="Sá»‘ káº¿t quáº£ tÃ¬m kiáº¿m",
                    info="Nhiá»u káº¿t quáº£ = ngá»¯ cáº£nh phong phÃº hÆ¡n nhÆ°ng cháº­m hÆ¡n",
                )

                gr.Markdown("### ğŸ“ Gá»£i Ã½ sá»­ dá»¥ng")
                gr.Markdown(
                    """
                - Äáº·t cÃ¢u há»i rÃµ rÃ ng vÃ  cá»¥ thá»ƒ
                - Sá»­ dá»¥ng tá»« khÃ³a cÃ³ trong tÃ i liá»‡u
                - CÃ¢u tráº£ lá»i sáº½ kÃ¨m theo trÃ­ch dáº«n nguá»“n (vÃ­ dá»¥: [TÃªn file, Trang X])
                """
                )

        def user(user_message, history):
            return "", history + [[user_message, None]]

        def bot(history, num_results):
            if history and history[-1][0]:
                bot_message = ask_question(history[-1][0], num_results)
                history[-1][1] = bot_message
            return history

        # Event handlers cho tab há»i Ä‘Ã¡p
        msg.submit(user, [msg, chatbot], [msg, chatbot], queue=False).then(
            bot, [chatbot, num_results], chatbot
        )
        submit_btn.click(user, [msg, chatbot], [msg, chatbot], queue=False).then(
            bot, [chatbot, num_results], chatbot
        )
        clear_btn.click(lambda: None, None, chatbot, queue=False)


demo.launch(share=False, server_name="localhost", server_port=7860)
