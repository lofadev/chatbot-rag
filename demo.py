import os
import shutil
import gradio as gr
from langchain_community.document_loaders import (
    PyMuPDFLoader,
    Docx2txtLoader,
    TextLoader,
)
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain.prompts import PromptTemplate
from dotenv import load_dotenv

# T·∫£i c√°c bi·∫øn m√¥i tr∆∞·ªùng (cho OpenAI API key)
load_dotenv()

# C√°c th∆∞ m·ª•c
DOCUMENTS_DIR = "documents"
INDEX_DIR = "faiss_index"

# ƒê·∫£m b·∫£o c√°c th∆∞ m·ª•c t·ªìn t·∫°i
os.makedirs(DOCUMENTS_DIR, exist_ok=True)
os.makedirs(INDEX_DIR, exist_ok=True)

# C·∫•u h√¨nh m·∫∑c ƒë·ªãnh cho chunking
DEFAULT_CONFIG = {
    "chunk_size": 1000,
    "chunk_overlap": 200,
    "strategy": "recursive",  # "recursive", "character", "token"
    "separators": ["\n\n", "\n", " ", ""],
    "length_function": "len",
}


# H√†m l·∫•y loader ph√π h·ª£p d·ª±a tr√™n ph·∫ßn m·ªü r·ªông c·ªßa file
def get_loader(file_path):
    try:
        # Ki·ªÉm tra file t·ªìn t·∫°i
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"Kh√¥ng t√¨m th·∫•y file: {file_path}")

        # Ki·ªÉm tra file c√≥ th·ªÉ ƒë·ªçc ƒë∆∞·ª£c
        if not os.access(file_path, os.R_OK):
            raise PermissionError(f"Kh√¥ng c√≥ quy·ªÅn ƒë·ªçc file: {file_path}")

        ext = os.path.splitext(file_path)[1].lower()

        if ext == ".pdf":
            return PyMuPDFLoader(file_path, extract_tables="markdown", mode="page")
        elif ext == ".docx":
            return Docx2txtLoader(file_path)
        elif ext in [".txt", ".md"]:
            return TextLoader(file_path, encoding="utf-8")
        else:
            raise ValueError(
                f"ƒê·ªãnh d·∫°ng file kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£: {ext}. Ch·ªâ h·ªó tr·ª£ PDF, DOCX, TXT, MD"
            )

    except FileNotFoundError as e:
        raise FileNotFoundError(f"L·ªói file kh√¥ng t·ªìn t·∫°i: {str(e)}")
    except PermissionError as e:
        raise PermissionError(f"L·ªói quy·ªÅn truy c·∫≠p: {str(e)}")
    except Exception as e:
        raise Exception(f"L·ªói khi t·∫°o loader cho file {file_path}: {str(e)}")


# H√†m x·ª≠ l√Ω m·ªôt t√†i li·ªáu ƒë∆°n l·∫ª v·ªõi metadata chi ti·∫øt
def ingest_document(file_path, config=None):
    try:
        if config is None:
            config = DEFAULT_CONFIG.copy()

        # Validate config
        if not isinstance(config, dict):
            raise TypeError("Config ph·∫£i l√† dictionary")

        required_keys = ["chunk_size", "chunk_overlap"]
        for key in required_keys:
            if key not in config:
                raise KeyError(f"Config thi·∫øu key b·∫Øt bu·ªôc: {key}")
            if not isinstance(config[key], int) or config[key] <= 0:
                raise ValueError(f"Config {key} ph·∫£i l√† s·ªë nguy√™n d∆∞∆°ng")

        filename = os.path.basename(file_path)

        # S·ª≠ d·ª•ng get_loader ƒë√£ ƒë∆∞·ª£c c·∫£i thi·ªán v·ªõi exception handling
        try:
            loader = get_loader(file_path)
            documents = loader.load()
        except Exception as e:
            raise Exception(f"L·ªói khi t·∫£i t√†i li·ªáu {filename}: {str(e)}")

        # Ki·ªÉm tra n·ªôi dung t√†i li·ªáu
        if not documents:
            raise ValueError(
                f"T√†i li·ªáu {filename} kh√¥ng c√≥ n·ªôi dung ho·∫∑c kh√¥ng th·ªÉ ƒë·ªçc ƒë∆∞·ª£c"
            )

        # C·∫£i thi·ªán metadata cho m·ªói document
        try:
            for doc in documents:
                if not hasattr(doc, "metadata"):
                    doc.metadata = {}

                doc.metadata.update(
                    {
                        "source_file": filename,
                        "file_path": file_path,
                        "file_type": os.path.splitext(filename)[1].lower(),
                        "processed_time": str(os.path.getmtime(file_path)),
                    }
                )

                # Th√™m page number n·∫øu c√≥ (c·ªông th√™m 1 ƒë·ªÉ b·∫Øt ƒë·∫ßu t·ª´ trang 1)
                if "page" in doc.metadata:
                    page_info = doc.metadata.get("page")
                    if page_info is not None and isinstance(page_info, (int, float)):
                        doc.metadata["page_number"] = int(page_info) + 1
                    else:
                        doc.metadata["page_number"] = page_info
                else:
                    # Kh√¥ng c√≥ th√¥ng tin trang
                    doc.metadata["page_number"] = "N/A"
        except Exception as e:
            raise Exception(f"L·ªói khi x·ª≠ l√Ω metadata cho t√†i li·ªáu {filename}: {str(e)}")

        # X·ª≠ l√Ω text splitting
        try:
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=config["chunk_size"],
                chunk_overlap=config["chunk_overlap"],
                length_function=len,
                separators=config.get("separators", ["\n\n", "\n", " ", ""]),
            )
            chunks = text_splitter.split_documents(documents)
        except Exception as e:
            raise Exception(f"L·ªói khi chia nh·ªè t√†i li·ªáu {filename}: {str(e)}")

        # Ki·ªÉm tra k·∫øt qu·∫£ splitting
        if not chunks:
            raise ValueError(f"Kh√¥ng th·ªÉ t·∫°o chunks t·ª´ t√†i li·ªáu {filename}")

        # Th√™m th√¥ng tin chunk index cho m·ªói chunk
        try:
            for i, chunk in enumerate(chunks):
                if not hasattr(chunk, "metadata"):
                    chunk.metadata = {}

                chunk.metadata.update(
                    {
                        "chunk_index": i,
                        "chunk_size": len(chunk.page_content),
                        "total_chunks": len(chunks),
                    }
                )
        except Exception as e:
            raise Exception(
                f"L·ªói khi th√™m metadata cho chunks c·ªßa t√†i li·ªáu {filename}: {str(e)}"
            )

        return chunks

    except (FileNotFoundError, PermissionError, ValueError, KeyError, TypeError) as e:
        # Re-raise specific exceptions v·ªõi th√¥ng b√°o g·ªëc
        raise e
    except Exception as e:
        raise Exception(f"L·ªói kh√¥ng x√°c ƒë·ªãnh khi x·ª≠ l√Ω t√†i li·ªáu {file_path}: {str(e)}")


# H√†m x√¢y d·ª±ng ho·∫∑c x√¢y d·ª±ng l·∫°i index v·ªõi c·∫•u h√¨nh chunking
def build_index(config=None):
    try:
        # Validate v√† setup config
        if config is None:
            config = DEFAULT_CONFIG.copy()

        if not isinstance(config, dict):
            raise TypeError("Config ph·∫£i l√† dictionary")

        # Validate required config keys
        required_keys = ["chunk_size", "chunk_overlap"]
        for key in required_keys:
            if key not in config:
                raise KeyError(f"Config thi·∫øu key b·∫Øt bu·ªôc: {key}")
            if not isinstance(config[key], int) or config[key] <= 0:
                raise ValueError(f"Config {key} ph·∫£i l√† s·ªë nguy√™n d∆∞∆°ng")

        # Ki·ªÉm tra th∆∞ m·ª•c documents t·ªìn t·∫°i
        if not os.path.exists(DOCUMENTS_DIR):
            raise FileNotFoundError(f"Th∆∞ m·ª•c documents kh√¥ng t·ªìn t·∫°i: {DOCUMENTS_DIR}")

        # X√≥a index c≈© n·∫øu c√≥
        try:
            if os.path.exists(INDEX_DIR):
                shutil.rmtree(INDEX_DIR)
        except PermissionError:
            raise PermissionError(f"Kh√¥ng c√≥ quy·ªÅn x√≥a th∆∞ m·ª•c index: {INDEX_DIR}")
        except Exception as e:
            raise Exception(f"L·ªói khi x√≥a index c≈©: {str(e)}")

        # T·∫°o l·∫°i th∆∞ m·ª•c index
        try:
            os.makedirs(INDEX_DIR, exist_ok=True)
        except Exception as e:
            raise Exception(f"L·ªói khi t·∫°o th∆∞ m·ª•c index: {str(e)}")

        all_chunks = []
        processed_files = []
        error_files = []

        # L·∫•y danh s√°ch files
        try:
            file_list = os.listdir(DOCUMENTS_DIR)
        except PermissionError:
            raise PermissionError(f"Kh√¥ng c√≥ quy·ªÅn ƒë·ªçc th∆∞ m·ª•c: {DOCUMENTS_DIR}")
        except Exception as e:
            raise Exception(f"L·ªói khi ƒë·ªçc th∆∞ m·ª•c documents: {str(e)}")

        # X·ª≠ l√Ω t·ª´ng file
        for filename in file_list:
            if filename.startswith("."):  # B·ªè qua hidden files
                continue

            file_path = os.path.join(DOCUMENTS_DIR, filename)

            # Ch·ªâ x·ª≠ l√Ω files, kh√¥ng ph·∫£i directories
            if not os.path.isfile(file_path):
                continue

            try:
                chunks = ingest_document(file_path, config)
                all_chunks.extend(chunks)
                processed_files.append(f"‚úÖ {filename}: {len(chunks)} chunks")
            except Exception as e:
                error_message = f"‚ùå {filename}: {str(e)}"
                error_files.append(error_message)
                processed_files.append(error_message)

        # Ki·ªÉm tra c√≥ documents ƒë·ªÉ index kh√¥ng
        if not all_chunks:
            if error_files:
                error_summary = "\n".join(error_files)
                return (
                    f"Kh√¥ng th·ªÉ t·∫°o index - t·∫•t c·∫£ files ƒë·ªÅu g·∫∑p l·ªói:\n{error_summary}"
                )
            else:
                return "Kh√¥ng c√≥ t√†i li·ªáu h·ª£p l·ªá ƒë·ªÉ t·∫°o index."

        # T·∫°o embeddings v√† vectorstore
        try:
            embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
        except Exception as e:
            raise Exception(
                f"L·ªói khi t·∫°o OpenAI embeddings: {str(e)}. Ki·ªÉm tra API key v√† k·∫øt n·ªëi m·∫°ng."
            )

        try:
            vectorstore = FAISS.from_documents(all_chunks, embeddings)
        except Exception as e:
            raise Exception(f"L·ªói khi t·∫°o FAISS vectorstore: {str(e)}")

        try:
            vectorstore.save_local(INDEX_DIR)
        except PermissionError:
            raise PermissionError(f"Kh√¥ng c√≥ quy·ªÅn ghi v√†o th∆∞ m·ª•c index: {INDEX_DIR}")
        except Exception as e:
            raise Exception(f"L·ªói khi l∆∞u vectorstore: {str(e)}")

        # T·∫°o k·∫øt qu·∫£ th√†nh c√¥ng
        success_count = len(processed_files) - len(error_files)
        result = f"üéâ Index ƒë∆∞·ª£c t·∫°o th√†nh c√¥ng!\n"
        result += f"üìä T·ªïng s·ªë chunks: {len(all_chunks)}\n"
        result += f"üìÅ Files x·ª≠ l√Ω th√†nh c√¥ng: {success_count}/{len(processed_files)}\n"
        result += f"‚öôÔ∏è C·∫•u h√¨nh chunking: K√≠ch th∆∞·ªõc {config['chunk_size']}, Overlap {config['chunk_overlap']}\n\n"

        if error_files:
            result += f"‚ö†Ô∏è {len(error_files)} file(s) g·∫∑p l·ªói:\n"

        result += "üìã Chi ti·∫øt x·ª≠ l√Ω:\n" + "\n".join(processed_files)
        return result

    except (TypeError, KeyError, ValueError, FileNotFoundError, PermissionError) as e:
        return f"L·ªói khi t·∫°o index: {str(e)}"
    except Exception as e:
        return f"L·ªói kh√¥ng x√°c ƒë·ªãnh khi t·∫°o index: {str(e)}"


# H√†m t·∫£i vectorstore
def load_vectorstore():
    try:
        # Ki·ªÉm tra th∆∞ m·ª•c index t·ªìn t·∫°i
        if not os.path.exists(INDEX_DIR):
            raise FileNotFoundError(f"Th∆∞ m·ª•c index kh√¥ng t·ªìn t·∫°i: {INDEX_DIR}")

        # Ki·ªÉm tra file index.faiss t·ªìn t·∫°i
        index_file = os.path.join(INDEX_DIR, "index.faiss")
        if not os.path.exists(index_file):
            return None  # Kh√¥ng c√≥ index, tr·∫£ v·ªÅ None (kh√¥ng ph·∫£i l·ªói)

        # Ki·ªÉm tra file index.pkl t·ªìn t·∫°i
        pkl_file = os.path.join(INDEX_DIR, "index.pkl")
        if not os.path.exists(pkl_file):
            raise FileNotFoundError(f"File index.pkl kh√¥ng t·ªìn t·∫°i: {pkl_file}")

        try:
            # T·∫°o embeddings
            embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
        except Exception as e:
            raise Exception(
                f"L·ªói khi t·∫°o OpenAI embeddings: {str(e)}. Ki·ªÉm tra API key v√† k·∫øt n·ªëi m·∫°ng."
            )

        try:
            # T·∫£i vectorstore
            vectorstore = FAISS.load_local(
                INDEX_DIR, embeddings, allow_dangerous_deserialization=True
            )
            return vectorstore
        except Exception as e:
            raise Exception(f"L·ªói khi t·∫£i vectorstore t·ª´ {INDEX_DIR}: {str(e)}")

    except FileNotFoundError as e:
        raise FileNotFoundError(str(e))
    except Exception as e:
        raise Exception(f"L·ªói kh√¥ng x√°c ƒë·ªãnh khi t·∫£i vectorstore: {str(e)}")


# H√†m t·∫£i l√™n v√† x·ª≠ l√Ω file
def upload_file(file):
    try:
        # Ki·ªÉm tra file c√≥ ƒë∆∞·ª£c t·∫£i l√™n
        if file is None:
            return "Kh√¥ng c√≥ file n√†o ƒë∆∞·ª£c t·∫£i l√™n."

        # Ki·ªÉm tra file object c√≥ name attribute
        if not hasattr(file, "name") or not file.name:
            return "File kh√¥ng h·ª£p l·ªá ho·∫∑c thi·∫øu th√¥ng tin t√™n file."

        # Ki·ªÉm tra file c√≥ t·ªìn t·∫°i trong temp location
        if not os.path.exists(file.name):
            return "File t·∫°m th·ªùi kh√¥ng t·ªìn t·∫°i. Vui l√≤ng th·ª≠ t·∫£i l√™n l·∫°i."

        filename = os.path.basename(file.name)

        # Validate filename
        if not filename or filename.startswith("."):
            return "T√™n file kh√¥ng h·ª£p l·ªá."

        # Ki·ªÉm tra ƒë·ªãnh d·∫°ng file ƒë∆∞·ª£c h·ªó tr·ª£
        ext = os.path.splitext(filename)[1].lower()
        supported_extensions = [".pdf", ".docx", ".txt", ".md"]
        if ext not in supported_extensions:
            return f"ƒê·ªãnh d·∫°ng file {ext} kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£. Ch·ªâ h·ªó tr·ª£: {', '.join(supported_extensions)}"

        # Ki·ªÉm tra k√≠ch th∆∞·ªõc file (gi·ªõi h·∫°n 100MB)
        file_size = os.path.getsize(file.name)
        max_size = 100 * 1024 * 1024  # 100MB
        if file_size > max_size:
            return f"File qu√° l·ªõn ({file_size / (1024*1024):.1f} MB). Gi·ªõi h·∫°n t·ªëi ƒëa l√† 100MB."

        file_path = os.path.join(DOCUMENTS_DIR, filename)

        # Ki·ªÉm tra file ƒë√£ t·ªìn t·∫°i
        if os.path.exists(file_path):
            return (
                f"File {filename} ƒë√£ t·ªìn t·∫°i. Vui l√≤ng x√≥a file c≈© ho·∫∑c ƒë·ªïi t√™n file."
            )

        try:
            # Copy file ƒë·∫øn th∆∞ m·ª•c documents
            shutil.copy(file.name, file_path)
        except PermissionError:
            return f"Kh√¥ng c√≥ quy·ªÅn ghi file v√†o th∆∞ m·ª•c {DOCUMENTS_DIR}."
        except shutil.Error as e:
            return f"L·ªói khi copy file: {str(e)}"
        except Exception as e:
            return f"L·ªói kh√¥ng x√°c ƒë·ªãnh khi l∆∞u file: {str(e)}"

        # Rebuild index sau khi t·∫£i l√™n
        try:
            config = DEFAULT_CONFIG.copy()
            result = build_index(config)
            return f"File {filename} ƒë√£ ƒë∆∞·ª£c t·∫£i l√™n th√†nh c√¥ng.\n\n{result}"
        except Exception as e:
            # N·∫øu build index th·∫•t b·∫°i, x√≥a file ƒë√£ upload ƒë·ªÉ tr√°nh inconsistency
            try:
                os.remove(file_path)
            except:
                pass
            return f"File {filename} ƒë√£ ƒë∆∞·ª£c t·∫£i l√™n nh∆∞ng g·∫∑p l·ªói khi ƒë√°nh index: {str(e)}"

    except Exception as e:
        return f"L·ªói kh√¥ng x√°c ƒë·ªãnh khi t·∫£i l√™n file: {str(e)}"


# H√†m li·ªát k√™ c√°c t√†i li·ªáu v·ªõi th√¥ng tin chi ti·∫øt
def list_documents():
    files = os.listdir(DOCUMENTS_DIR)
    if not files:
        return "No documents."

    file_info = []
    for filename in files:
        if filename.startswith("."):
            continue
        file_path = os.path.join(DOCUMENTS_DIR, filename)
        if os.path.isfile(file_path):
            size = os.path.getsize(file_path)
            size_mb = round(size / (1024 * 1024), 2)
            ext = os.path.splitext(filename)[1].lower()
            file_info.append(f"üìÑ {filename} ({size_mb} MB, {ext})")

    return "\n".join(file_info) if file_info else "No valid documents."


# H√†m x√≥a t√†i li·ªáu
def delete_document(filename):
    try:
        # Validate filename
        if not filename or not isinstance(filename, str):
            return "T√™n file kh√¥ng h·ª£p l·ªá."

        # Sanitize filename ƒë·ªÉ tr√°nh path traversal
        filename = os.path.basename(filename.strip())
        if not filename or filename.startswith(".") or filename == "..":
            return "T√™n file kh√¥ng h·ª£p l·ªá ho·∫∑c kh√¥ng an to√†n."

        file_path = os.path.join(DOCUMENTS_DIR, filename)

        # ƒê·∫£m b·∫£o file path n·∫±m trong DOCUMENTS_DIR (security check)
        if not os.path.abspath(file_path).startswith(os.path.abspath(DOCUMENTS_DIR)):
            return "ƒê∆∞·ªùng d·∫´n file kh√¥ng h·ª£p l·ªá."

        # Ki·ªÉm tra file c√≥ t·ªìn t·∫°i
        if not os.path.exists(file_path):
            return f"Kh√¥ng t√¨m th·∫•y file: {filename}"

        # Ki·ªÉm tra ƒë√¢y c√≥ ph·∫£i l√† file kh√¥ng (kh√¥ng ph·∫£i th∆∞ m·ª•c)
        if not os.path.isfile(file_path):
            return f"{filename} kh√¥ng ph·∫£i l√† file h·ª£p l·ªá."

        try:
            # X√≥a file
            os.remove(file_path)
        except PermissionError:
            return f"Kh√¥ng c√≥ quy·ªÅn x√≥a file: {filename}"
        except Exception as e:
            return f"L·ªói khi x√≥a file {filename}: {str(e)}"

        # Rebuild index sau khi x√≥a
        try:
            config = DEFAULT_CONFIG.copy()
            result = build_index(config)
            return f"File {filename} ƒë√£ ƒë∆∞·ª£c x√≥a th√†nh c√¥ng.\n\n{result}"
        except Exception as e:
            return f"File {filename} ƒë√£ ƒë∆∞·ª£c x√≥a nh∆∞ng g·∫∑p l·ªói khi c·∫≠p nh·∫≠t index: {str(e)}"

    except Exception as e:
        return f"L·ªói kh√¥ng x√°c ƒë·ªãnh khi x√≥a file: {str(e)}"


# H√†m ƒë√°nh index l·∫°i v·ªõi c·∫•u h√¨nh hi·ªán t·∫°i
def reindex():
    config = DEFAULT_CONFIG.copy()
    return build_index(config)


# Prompt t√πy ch·ªânh cho LLM v·ªõi h∆∞·ªõng d·∫´n tr√≠ch d·∫´n chi ti·∫øt
prompt_template = """
B·∫°n l√† m·ªôt tr·ª£ l√Ω AI t√¨m ki·∫øm th√¥ng tin th√¥ng minh, b·∫°n c√≥ th·ªÉ t√¨m ki·∫øm th√¥ng tin trong c√°c t√†i li·ªáu ƒë√£ ƒë∆∞·ª£c ƒë√°nh index.
S·ª≠ d·ª•ng CH√çNH X√ÅC th√¥ng tin t·ª´ c√°c ƒëo·∫°n vƒÉn b·∫£n d∆∞·ªõi ƒë√¢y ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi. 
N·∫øu b·∫°n kh√¥ng bi·∫øt c√¢u tr·∫£ l·ªùi t·ª´ ng·ªØ c·∫£nh ƒë√£ cho, h√£y n√≥i r·∫±ng b·∫°n kh√¥ng bi·∫øt, ƒë·ª´ng b·ªãa ƒë·∫∑t th√¥ng tin.
S·ª≠ d·ª•ng ng√¥n ng·ªØ t·ª± nhi√™n, th√¢n thi·ªán v·ªõi ng∆∞·ªùi d√πng.
Tr·∫£ l·ªùi b·∫±ng c√πng ng√¥n ng·ªØ v·ªõi c√¢u h·ªèi (Ti·∫øng Vi·ªát ho·∫∑c Ti·∫øng Anh).

QUY T·∫ÆC TR√çCH D·∫™N B·∫ÆT BU·ªòC:
- B·∫ÆT BU·ªòC ph·∫£i tr√≠ch d·∫´n ngu·ªìn cho M·ªñI th√¥ng tin b·∫°n cung c·∫•p
- S·ª¨ D·ª§NG CH√çNH X√ÅC tr√≠ch d·∫´n ƒë√£ ƒë∆∞·ª£c cung c·∫•p trong t·ª´ng ƒëo·∫°n vƒÉn b·∫£n
- M·ªói ƒëo·∫°n vƒÉn b·∫£n ƒë√£ c√≥ s·∫µn "Ngu·ªìn tr√≠ch d·∫´n:" ·ªü cu·ªëi - PH·∫¢I s·ª≠ d·ª•ng ƒë√∫ng tr√≠ch d·∫´n n√†y
- KH√îNG ƒë∆∞·ª£c t·ª± t·∫°o tr√≠ch d·∫´n m·ªõi, ch·ªâ s·ª≠ d·ª•ng tr√≠ch d·∫´n c√≥ s·∫µn trong ng·ªØ c·∫£nh
- Khi tham kh·∫£o th√¥ng tin t·ª´ m·ªôt ƒëo·∫°n vƒÉn b·∫£n, LU√îN include tr√≠ch d·∫´n c·ªßa ƒëo·∫°n ƒë√≥
- N·∫øu th√¥ng tin ƒë·∫øn t·ª´ nhi·ªÅu ƒëo·∫°n vƒÉn b·∫£n, li·ªát k√™ T·∫§T C·∫¢ tr√≠ch d·∫´n li√™n quan

C√ÅCH TR√çCH D·∫™N:
- Sau m·ªói th√¥ng tin, th√™m citation trong ngo·∫∑c vu√¥ng
- V√≠ d·ª•: "Doanh thu nƒÉm 2023 l√† 100 tri·ªáu ƒë·ªìng [bao_cao_tai_chinh.pdf, Trang 5]"
- V·ªõi nhi·ªÅu ngu·ªìn: "Th√¥ng tin n√†y ƒë∆∞·ª£c x√°c nh·∫≠n [file1.pdf, Trang 2] [file2.pdf, Trang 7]"

Ng·ªØ c·∫£nh v·ªõi tr√≠ch d·∫´n:
{context}

C√¢u h·ªèi: {question}

Tr·∫£ l·ªùi chi ti·∫øt (B·∫ÆT BU·ªòC bao g·ªìm tr√≠ch d·∫´n ngu·ªìn cho m·ªçi th√¥ng tin):
"""

PROMPT = PromptTemplate(
    template=prompt_template, input_variables=["context", "question"]
)


# H√†m c·∫£i thi·ªán context v·ªõi metadata chi ti·∫øt - ch·ªâ hi·ªÉn th·ªã file v√† trang
def format_docs_with_metadata(docs):
    formatted_docs = []
    for doc in docs:
        metadata = doc.metadata
        source_file = metadata.get("source_file", "Unknown file")

        # X·ª≠ l√Ω s·ªë trang (∆∞u ti√™n page_number ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω, kh√¥ng th√¨ x·ª≠ l√Ω page g·ªëc)
        if "page_number" in metadata and metadata["page_number"] != "N/A":
            # page_number ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω trong ingest_document
            display_page = metadata["page_number"]
            citation = f"[{source_file}, Trang {display_page}]"
        elif "page" in metadata and metadata["page"] != "N/A":
            # Fallback: s·ª≠ d·ª•ng page g·ªëc v√† c·ªông th√™m 1
            page_info = metadata["page"]
            if isinstance(page_info, (int, float)):
                display_page = int(page_info) + 1
            else:
                display_page = page_info
            citation = f"[{source_file}, Trang {display_page}]"
        else:
            # Kh√¥ng c√≥ th√¥ng tin trang, ch·ªâ hi·ªÉn th·ªã file
            citation = f"[{source_file}]"

        # Format content v·ªõi citation r√µ r√†ng h∆°n - kh√¥ng hi·ªÉn th·ªã th√¥ng tin chunk
        content = f"=== ƒêO·∫†N VƒÇN B·∫¢N T·ª™ {citation} ===\n{doc.page_content}\n=== K·∫æT TH√öC ƒêO·∫†N VƒÇN B·∫¢N ===\nNgu·ªìn tr√≠ch d·∫´n: {citation}"
        formatted_docs.append(content)

    return "\n\n---\n\n".join(formatted_docs)


# H√†m cho h·ªèi ƒë√°p v·ªõi citation ch√≠nh x√°c
def ask_question(question, num_results=5):
    try:
        # Validate input parameters
        if not question or not isinstance(question, str):
            return "C√¢u h·ªèi kh√¥ng h·ª£p l·ªá. Vui l√≤ng nh·∫≠p m·ªôt c√¢u h·ªèi."

        question = question.strip()
        if not question:
            return "C√¢u h·ªèi kh√¥ng th·ªÉ ƒë·ªÉ tr·ªëng."

        if len(question) > 1000:
            return "C√¢u h·ªèi qu√° d√†i (t·ªëi ƒëa 1000 k√Ω t·ª±). Vui l√≤ng r√∫t g·ªçn c√¢u h·ªèi."

        # Validate num_results
        if not isinstance(num_results, int) or num_results < 1 or num_results > 20:
            num_results = 5  # Set default value if invalid

        # T·∫£i vectorstore
        try:
            vectorstore = load_vectorstore()
        except Exception as e:
            return f"L·ªói khi t·∫£i vectorstore: {str(e)}"

        if vectorstore is None:
            return "Kh√¥ng c√≥ index n√†o kh·∫£ d·ª•ng. Vui l√≤ng t·∫£i l√™n t√†i li·ªáu v√† t·∫°o index tr∆∞·ªõc."

        # T·∫°o LLM
        try:
            llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
        except Exception as e:
            return (
                f"L·ªói khi t·∫°o ChatOpenAI: {str(e)}. Ki·ªÉm tra API key v√† k·∫øt n·ªëi m·∫°ng."
            )

        # T·∫°o retriever v√† search documents
        try:
            retriever = vectorstore.as_retriever(search_kwargs={"k": num_results})
            relevant_docs = retriever.get_relevant_documents(question)
        except Exception as e:
            return f"L·ªói khi t√¨m ki·∫øm t√†i li·ªáu li√™n quan: {str(e)}"

        # Ki·ªÉm tra c√≥ t√†i li·ªáu li√™n quan kh√¥ng
        if not relevant_docs:
            return "Kh√¥ng t√¨m th·∫•y th√¥ng tin li√™n quan trong t√†i li·ªáu. H√£y th·ª≠ c√¢u h·ªèi kh√°c ho·∫∑c ki·ªÉm tra l·∫°i t·ª´ kh√≥a."

        # Format context v·ªõi metadata chi ti·∫øt
        try:
            formatted_context = format_docs_with_metadata(relevant_docs)
        except Exception as e:
            return f"L·ªói khi format context: {str(e)}"

        # T·∫°o prompt v·ªõi context ƒë√£ ƒë∆∞·ª£c format
        try:
            formatted_prompt = PROMPT.format(
                context=formatted_context, question=question
            )
        except Exception as e:
            return f"L·ªói khi t·∫°o prompt: {str(e)}"

        # G·ªçi LLM v·ªõi prompt ƒë√£ format
        try:
            result = llm.invoke(formatted_prompt)
        except Exception as e:
            return f"L·ªói khi g·ªçi OpenAI API: {str(e)}. Ki·ªÉm tra API key, quota v√† k·∫øt n·ªëi m·∫°ng."

        # Tr·∫£ v·ªÅ n·ªôi dung text t·ª´ response
        try:
            if hasattr(result, "content"):
                response_content = result.content
            else:
                response_content = str(result)

            # Ki·ªÉm tra response kh√¥ng tr·ªëng
            if not response_content or not response_content.strip():
                return "LLM kh√¥ng tr·∫£ l·ªùi ƒë∆∞·ª£c c√¢u h·ªèi. H√£y th·ª≠ c√¢u h·ªèi kh√°c."

            return response_content.strip()

        except Exception as e:
            return f"L·ªói khi x·ª≠ l√Ω response t·ª´ LLM: {str(e)}"

    except Exception as e:
        return f"L·ªói kh√¥ng x√°c ƒë·ªãnh khi x·ª≠ l√Ω c√¢u h·ªèi: {str(e)}"


# Giao di·ªán Gradio
with gr.Blocks(title="RAG Document QA System", theme=gr.themes.Default()) as demo:
    gr.Markdown("# ü§ñ RAG-based Document QA System")
    gr.Markdown(
        "H·ªá th·ªëng h·ªèi ƒë√°p th√¥ng minh d·ª±a tr√™n t√†i li·ªáu v·ªõi kh·∫£ nƒÉng tr√≠ch d·∫´n ngu·ªìn chi ti·∫øt"
    )

    with gr.Tab("üìÑ Qu·∫£n l√Ω T√†i li·ªáu"):
        gr.Markdown("### T·∫£i l√™n v√† qu·∫£n l√Ω t√†i li·ªáu")

        with gr.Row():
            with gr.Column(scale=2):
                file_upload = gr.File(
                    label="Ch·ªçn t√†i li·ªáu (PDF, DOCX, TXT, MD)",
                    file_types=[".pdf", ".docx", ".txt", ".md"],
                )
                upload_button = gr.Button("üì§ T·∫£i l√™n v√† ƒê√°nh index", variant="primary")
                upload_output = gr.Textbox(label="Tr·∫°ng th√°i t·∫£i l√™n", lines=5)

            with gr.Column(scale=1):
                list_button = gr.Button("üìã Li·ªát k√™ t√†i li·ªáu")
                documents_list = gr.Textbox(label="Danh s√°ch t√†i li·ªáu", lines=8)

        gr.Markdown("---")

        with gr.Row():
            delete_input = gr.Textbox(
                label="T√™n file c·∫ßn x√≥a", placeholder="V√≠ d·ª•: document.pdf"
            )
            delete_button = gr.Button("üóëÔ∏è X√≥a t√†i li·ªáu", variant="stop")
            delete_output = gr.Textbox(label="Tr·∫°ng th√°i x√≥a", lines=3)

        with gr.Row():
            reindex_button = gr.Button("üîÑ ƒê√°nh index l·∫°i to√†n b·ªô", variant="secondary")
            reindex_output = gr.Textbox(label="Tr·∫°ng th√°i ƒë√°nh index", lines=5)

        # Event handlers cho tab Admin
        upload_button.click(upload_file, inputs=file_upload, outputs=upload_output)
        list_button.click(list_documents, outputs=documents_list)
        delete_button.click(delete_document, inputs=delete_input, outputs=delete_output)
        reindex_button.click(reindex, outputs=reindex_output)

    with gr.Tab("üí¨ H·ªèi ƒë√°p"):
        gr.Markdown("### ƒê·∫∑t c√¢u h·ªèi v·ªÅ t√†i li·ªáu")
        gr.Markdown(
            "H·ªá th·ªëng s·∫Ω t√¨m ki·∫øm th√¥ng tin li√™n quan v√† tr·∫£ l·ªùi k√®m tr√≠ch d·∫´n ngu·ªìn"
        )

        with gr.Row():
            with gr.Column(scale=3):
                chatbot = gr.Chatbot(
                    height=500, label="Cu·ªôc h·ªôi tho·∫°i", show_label=True
                )

                with gr.Row():
                    msg = gr.Textbox(
                        label="C√¢u h·ªèi c·ªßa b·∫°n",
                        placeholder="V√≠ d·ª•: T√†i li·ªáu n√≥i g√¨ v·ªÅ ch√≠nh s√°ch b·∫£o m·∫≠t?",
                        lines=2,
                        scale=4,
                    )
                    submit_btn = gr.Button("üöÄ G·ª≠i", variant="primary", scale=1)
                    clear_btn = gr.Button("üóëÔ∏è X√≥a", variant="secondary", scale=1)

            with gr.Column(scale=1):
                gr.Markdown("### ‚ö° T√πy ch·ªçn t√¨m ki·∫øm")
                num_results = gr.Slider(
                    minimum=1,
                    maximum=10,
                    value=5,
                    step=1,
                    label="S·ªë k·∫øt qu·∫£ t√¨m ki·∫øm",
                    info="Nhi·ªÅu k·∫øt qu·∫£ = ng·ªØ c·∫£nh phong ph√∫ h∆°n nh∆∞ng ch·∫≠m h∆°n",
                )

                gr.Markdown("### üìù G·ª£i √Ω s·ª≠ d·ª•ng")
                gr.Markdown(
                    """
                - ƒê·∫∑t c√¢u h·ªèi r√µ r√†ng v√† c·ª• th·ªÉ
                - S·ª≠ d·ª•ng t·ª´ kh√≥a c√≥ trong t√†i li·ªáu
                - C√¢u tr·∫£ l·ªùi s·∫Ω k√®m theo tr√≠ch d·∫´n ngu·ªìn (v√≠ d·ª•: [T√™n file, Trang X])
                """
                )

        def user(user_message, history):
            return "", history + [[user_message, None]]

        def bot(history, num_results):
            if history and history[-1][0]:
                bot_message = ask_question(history[-1][0], num_results)
                history[-1][1] = bot_message
            return history

        # Event handlers cho tab h·ªèi ƒë√°p
        msg.submit(user, [msg, chatbot], [msg, chatbot], queue=False).then(
            bot, [chatbot, num_results], chatbot
        )
        submit_btn.click(user, [msg, chatbot], [msg, chatbot], queue=False).then(
            bot, [chatbot, num_results], chatbot
        )
        clear_btn.click(lambda: None, None, chatbot, queue=False)


demo.launch(share=False, server_name="localhost", server_port=7860)
